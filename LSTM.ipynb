{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tolfqSYiqFFf",
        "outputId": "c4d2a393-7e8e-47bd-e316-3716c386708c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "og (20800, 5)\n",
            "(18285, 4) (18285,)\n"
          ]
        }
      ],
      "source": [
        "### IMPORTS\n",
        "# TensorFlow\n",
        "# import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "# Sci-kit Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "# Outros Auxiliares\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "## inicializando dataset e dividindo entre dados e rotulos\n",
        "df = pd.read_csv(\"fake_train.csv\")\n",
        "print(\"og\",df.shape)\n",
        "df = df.dropna()\n",
        "X = df.drop('label',axis=1)\n",
        "y = df['label']\n",
        "print(X.shape, y.shape)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### PRÉ-PROCESSAMENTO\n",
        "# resetando index\n",
        "docs = X.copy()\n",
        "docs.reset_index(inplace=True)\n",
        "\n",
        "ps = PorterStemmer()\n",
        "corpus=[]\n",
        "\n",
        "# removendo pontuação e stopwords, fazendo stemming\n",
        "for i in range(0,len(docs)):\n",
        "  doc = re.sub('[^a-zA-Z]', ' ', docs['title'][i])\n",
        "  doc = doc.lower()\n",
        "  doc = doc.split()\n",
        "  doc = [ps.stem(word) for word in doc if (not word in stopwords.words('english'))]\n",
        "  doc = ' '.join(doc)\n",
        "  corpus.append(doc)\n",
        "# print(corpus)\n",
        "\n",
        "# onehot encoder\n",
        "vocab_size = 18000\n",
        "onehot_repr = [one_hot(words, vocab_size) for words in corpus]\n",
        "\n",
        "# formatando pra embedding\n",
        "max_len = 20\n",
        "embeded_docs = pad_sequences(onehot_repr, maxlen = max_len)"
      ],
      "metadata": {
        "id": "3AxjVF8Dzgag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### MODELO\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 40, input_length=max_len))\n",
        "model.add(LSTM(100, activation=\"relu\"))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY_G9RYGJats",
        "outputId": "d1a082a4-b546-4993-f02f-782699c1eed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 20, 40)            720000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               56400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 776501 (2.96 MB)\n",
            "Trainable params: 776501 (2.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = np.array(embeded_docs)\n",
        "y_final = np.array(y)\n",
        "print(X_final.shape,y_final.shape)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_final,y_final,test_size=0.3,random_state=42)\n",
        "# treinamento\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)\n",
        "y_pred = (model.predict(X_test) > 0.5)\n",
        "y_pred\n",
        "print(\"\\nAccuracy: \",accuracy_score(y_test,y_pred)),\n",
        "confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pF8CSTkCm60",
        "outputId": "03c8b57f-0dbb-4e7d-c3c3-0022b357c302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18285, 20) (18285,)\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 10s 41ms/step - loss: 0.1040 - accuracy: 0.8415 - val_loss: 0.0579 - val_accuracy: 0.9213\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.0368 - accuracy: 0.9519 - val_loss: 0.0567 - val_accuracy: 0.9244\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 11s 54ms/step - loss: 0.0220 - accuracy: 0.9735 - val_loss: 0.0615 - val_accuracy: 0.9240\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.9839 - val_loss: 0.0610 - val_accuracy: 0.9240\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0103 - accuracy: 0.9884 - val_loss: 0.0666 - val_accuracy: 0.9207\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.0079 - accuracy: 0.9916 - val_loss: 0.0652 - val_accuracy: 0.9213\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0060 - accuracy: 0.9935 - val_loss: 0.0705 - val_accuracy: 0.9191\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0053 - accuracy: 0.9944 - val_loss: 0.0652 - val_accuracy: 0.9247\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0039 - accuracy: 0.9962 - val_loss: 0.0758 - val_accuracy: 0.9141\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0039 - accuracy: 0.9959 - val_loss: 0.0678 - val_accuracy: 0.9227\n",
            "172/172 [==============================] - 1s 7ms/step\n",
            "\n",
            "Accuracy:  0.9227123587313161\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2840,  267],\n",
              "       [ 157, 2222]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lstm é um tipo de rnn\n",
        "\n",
        "o problema da rnn é toda a memoria é long-term e ao longo do tempo isso vai se acumulando a ponto q a info nova perde valor\n",
        "\n",
        "célula state da lstm > 3 gates\n",
        "\n",
        "3 gates indo de 0-1: forget (regula o que deve ser esquecido), input (oq deve ser adicionado/updatado) e output (o que deve influenciar no output desse passo específico)"
      ],
      "metadata": {
        "id": "rX-vCC4jAOao"
      }
    }
  ]
}